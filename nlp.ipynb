{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json\n",
    "import spacy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = json.load(open('./input/cooking_train.json', 'r'))\n",
    "test = json.load(open('./input/cooking_test.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "36475ab00914ab8f9c624f2a187ebc21ce66d059"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "8d2882cfba41d869edc2dfb4f63daca74ae43c2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9774"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "f37dbc88b01ff254ad72720ad8eb7f52e325206e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'chinese',\n",
       " 'id': 29565,\n",
       " 'ingredients': ['romaine lettuce',\n",
       "  'sliced almonds',\n",
       "  'vegetable oil',\n",
       "  'scallions',\n",
       "  'soy sauce',\n",
       "  'cooked chicken',\n",
       "  'napa cabbage',\n",
       "  'chopped cilantro fresh',\n",
       "  'sugar',\n",
       "  'sesame seeds',\n",
       "  'wonton wrappers',\n",
       "  'fresh lemon juice',\n",
       "  'white vinegar',\n",
       "  'black pepper',\n",
       "  'sesame oil',\n",
       "  'salt',\n",
       "  'snow peas']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train + test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af77eb4e2182248584f933db2ae7b7a5d8da39d8"
   },
   "source": [
    "## Count unique ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "c72005240bada1f90c5650ebf3733e74ce97bb60"
   },
   "outputs": [],
   "source": [
    "train_meta = pd.DataFrame(index=[r['id'] for r in train], data={\n",
    "    'ingred_len': [len(r['ingredients']) for r in train],\n",
    "    'cuisine': [r['cuisine'] for r in train],\n",
    "    'train': 1\n",
    "})\n",
    "\n",
    "test_meta = pd.DataFrame(index=[r['id'] for r in test], data={\n",
    "    'ingred_len': [len(r['ingredients']) for r in test],\n",
    "    'train': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "29c6f2be9088b65f0509315ee4ebe54d599db7ad",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingred_len</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29565</th>\n",
       "      <td>17</td>\n",
       "      <td>chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15528</th>\n",
       "      <td>8</td>\n",
       "      <td>italian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38015</th>\n",
       "      <td>15</td>\n",
       "      <td>cajun_creole</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20511</th>\n",
       "      <td>19</td>\n",
       "      <td>italian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44111</th>\n",
       "      <td>14</td>\n",
       "      <td>chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ingred_len       cuisine  train\n",
       "29565          17       chinese      1\n",
       "15528           8       italian      1\n",
       "38015          15  cajun_creole      1\n",
       "20511          19       italian      1\n",
       "44111          14       chinese      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "b9d3f230fbb4a59d9e394eb3aa0f4a2e8c9e4e6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39774"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.concat([train_meta, test_meta], sort=True)\n",
    "len(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing ingredients using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /home/kk385830/miniconda3/envs/kaggle-cooking/lib/python3.6/site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/kk385830/miniconda3/envs/kaggle-cooking/lib/python3.6/site-packages/en_core_web_sm\n",
      "    -->\n",
      "    /home/kk385830/miniconda3/envs/kaggle-cooking/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'romaine lettuce'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe = all_data[0]\n",
    "ingredient = recipe['ingredients'][0]\n",
    "ingredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_recipe(recipe, nlp=nlp):\n",
    "    recipe_tokens = nlp(', '.join(recipe['ingredients']))\n",
    "    nouns = [t for t in recipe_tokens if t.pos == spacy.parts_of_speech.NOUN]\n",
    "    modifiers = [t for t in recipe_tokens if t.is_alpha and not t in set(nouns)]\n",
    "    return {\n",
    "        'nouns': nouns,\n",
    "        'modifiers': modifiers\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39774/39774 [08:39<00:00, 76.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 51min 57s, sys: 7.7 s, total: 2h 52min 4s\n",
      "Wall time: 8min 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ingred_maps = [process_recipe(recipe) for recipe in tqdm(all_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nouns': [romaine,\n",
       "  lettuce,\n",
       "  vegetable,\n",
       "  oil,\n",
       "  scallions,\n",
       "  soy,\n",
       "  sauce,\n",
       "  chicken,\n",
       "  cabbage,\n",
       "  cilantro,\n",
       "  sugar,\n",
       "  sesame,\n",
       "  seeds,\n",
       "  wrappers,\n",
       "  lemon,\n",
       "  juice,\n",
       "  vinegar,\n",
       "  pepper,\n",
       "  oil,\n",
       "  salt,\n",
       "  snow,\n",
       "  peas],\n",
       " 'modifiers': [sliced,\n",
       "  almonds,\n",
       "  cooked,\n",
       "  napa,\n",
       "  chopped,\n",
       "  fresh,\n",
       "  wonton,\n",
       "  fresh,\n",
       "  white,\n",
       "  black,\n",
       "  sesame]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingred_maps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not nearly perfect, but using a larger model should improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39774it [00:28, 1392.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 s, sys: 592 ms, total: 32.2 s\n",
      "Wall time: 28.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "noun_counts = [\n",
    "    pd.DataFrame(\n",
    "        data=[[\n",
    "            recipe.get('cuisine', None), \n",
    "            len(im['nouns']), \n",
    "            len(im['modifiers'])]],\n",
    "        columns=['label', 'len_nouns', 'len_modifiers'],\n",
    "        index=[recipe['id']]\n",
    "    ) for recipe, im in tqdm(zip(all_data, ingred_maps))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.04 s, sys: 272 ms, total: 6.32 s\n",
      "Wall time: 6.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nc_df = pd.concat(noun_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>len_nouns</th>\n",
       "      <th>len_modifiers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39122</th>\n",
       "      <td>french</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45567</th>\n",
       "      <td>chinese</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47032</th>\n",
       "      <td>french</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14325</th>\n",
       "      <td>indian</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>korean</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  len_nouns  len_modifiers\n",
       "39122   french         16              6\n",
       "45567  chinese         16              6\n",
       "47032   french         10              6\n",
       "14325   indian         28              7\n",
       "24999   korean         20              4"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_nouns</th>\n",
       "      <th>len_modifiers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.915246</td>\n",
       "      <td>5.665963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.540612</td>\n",
       "      <td>3.367649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      len_nouns  len_modifiers\n",
       "min    0.000000       0.000000\n",
       "max   99.000000      42.000000\n",
       "mean  14.915246       5.665963\n",
       "std    6.540612       3.367649"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_df.agg(['min', 'max', 'mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like by using just nouns we can greatly reduce the number of input parameters to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>len_nouns</th>\n",
       "      <th>len_modifiers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29570</th>\n",
       "      <td>thai</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10816</th>\n",
       "      <td>greek</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16116</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label  len_nouns  len_modifiers\n",
       "29570      thai          0              1\n",
       "10816     greek          0              1\n",
       "16116  japanese          0              1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_df[nc_df['len_nouns'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 3 samples should not throw a model off, but let's remember about them for checking whether a larger model really improves the POS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "852"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nc_df[nc_df['len_modifiers'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 824 ms, sys: 52 ms, total: 876 ms\n",
      "Wall time: 871 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unique_nouns = set().union(*[set([noun.text for noun in im['nouns']]) for im in ingred_maps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2143"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_nouns)  # reducing feature space by >30%, not bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2baaa402da2e8c3f810fe815c0d9dcea853c78d"
   },
   "source": [
    "# Generating vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_md==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/en_core_web_md-2.0.0.tar.gz#egg=en_core_web_md==2.0.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/en_core_web_md-2.0.0.tar.gz (120.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 120.9MB 1.1MB/s \n",
      "\u001b[?25hInstalling collected packages: en-core-web-md\n",
      "  Running setup.py install for en-core-web-md ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed en-core-web-md-2.0.0\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/kk385830/miniconda3/envs/kaggle-cooking/lib/python3.6/site-packages/en_core_web_md\n",
      "    -->\n",
      "    /home/kk385830/miniconda3/envs/kaggle-cooking/lib/python3.6/site-packages/spacy/data/en_core_web_md\n",
      "\n",
      "    You can now load the model via spacy.load('en_core_web_md')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_bigger = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_uuid": "c35b10b794d1b696ac13f5d8059fa366c011a630"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_uuid": "fdf21c3e0736910d021c9a20430e8a182ea1fbb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39774\n",
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 6.89 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_recipes = train + test\n",
    "print(len(all_recipes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ingredients(recipe_list: List[dict]) -> List[str]:\n",
    "    noun_lists = [process_recipe(recipe, nlp=nlp_bigger)['nouns'] for recipe in recipe_list]\n",
    "    return [\" \".join([noun.text for noun in nouns]) for nouns in noun_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 55s, sys: 132 ms, total: 3min 55s\n",
      "Wall time: 11.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "len(preprocess_ingredients(all_recipes[:1000]))  # will take 30x that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "_uuid": "eee5bafd4d592329dd8d08141d48419ccdca117c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(1, 2220)\n",
      "CPU times: user 2h 31min 23s, sys: 6.57 s, total: 2h 31min 30s\n",
      "Wall time: 7min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_ingredients = preprocess_ingredients(all_recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(39774, 2220)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "all_vectors = vectorizer.fit_transform(all_ingredients)\n",
    "print(type(all_vectors))\n",
    "assert(len(all_recipes) == all_vectors.shape[0])\n",
    "print(all_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature space is significantly smaller - let's see if we can reduce it further and generate bigrams that will actually capture the order of ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_popular_ingredients(ingredients: List[str], threshold: int = 10):    \n",
    "    joined_ingredients = \" \".join(ingredients).split(\" \")\n",
    "    unique, counts = np.unique(joined_ingredients, return_counts=True)\n",
    "    popular_enough = set(unique[counts > threshold])\n",
    "    print(f\"Using {len(popular_enough)} most popular ingredients\")\n",
    "    filtered_ingredients = [\" \".join([word for word in ingred_str.split(\" \") if word in popular_enough]) for ingred_str in ingredients]\n",
    "    return filtered_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 38 most popular ingredients\n",
      "CPU times: user 3.56 s, sys: 140 ms, total: 3.7 s\n",
      "Wall time: 657 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filtered_ingredients = keep_popular_ingredients(all_ingredients, threshold=len(all_ingredients)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lettuce almonds vegetable oil scallions soy sauce chicken napa cabbage cilantro sugar sesame seeds wonton wrappers lemon juice vinegar pepper sesame oil salt snow peas',\n",
       " 'pistachios fig bread ciabatta olive oil sugar wine vinegar water cheese',\n",
       " 'oil lemon chili sauce shrimp butter sauce lemon juice ground pepper paprika cloves oregano bread worcestershire sauce seasoning parsley',\n",
       " 'basil olive oil potato gnocchi garlic ground beef pepper meatballs cream breadcrumbs baby spinach leaves cheese worcestershire sauce onion seasoning eggs salt sodium chicken broth sea salt bay leaf',\n",
       " 'honey mushroom tamari soy sauce snow peas oil pepper baby corn chestnut mushrooms garlic ginger root chili peppers lemon wine vinegar noodles',\n",
       " 'sugar cooking spray purpose flour butter buttermilk baking soda baking powder corn meal eggs salt',\n",
       " 'egg whites lemon juice food coloring sugar margarine spread milk crumbs lime juice',\n",
       " 'corn meal olive oil rosemary thyme sage salt pizza doughs cooking spray leaf parsley',\n",
       " 'eggs almonds bell pepper onions thyme cloves ground turkey bread crumbs bay leaves almonds tomatoes olive oil salt chicken broth parsley',\n",
       " 'water pepper salt chicken broth onions ground ginger flour sesame oil eggs garlic']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ingredients[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vegetable oil soy sauce chicken cilantro sugar lemon juice vinegar pepper oil salt',\n",
       " 'olive oil sugar wine vinegar water cheese',\n",
       " 'oil lemon chili sauce butter sauce lemon juice ground pepper cloves sauce',\n",
       " 'olive oil garlic ground pepper cream leaves cheese sauce onion eggs salt chicken broth salt',\n",
       " 'soy sauce oil pepper corn garlic ginger chili lemon wine vinegar',\n",
       " 'sugar purpose flour butter powder corn eggs salt',\n",
       " 'lemon juice sugar milk lime juice',\n",
       " 'corn olive oil salt',\n",
       " 'eggs bell pepper onions cloves ground leaves tomatoes olive oil salt chicken broth',\n",
       " 'water pepper salt chicken broth onions ground ginger flour oil eggs garlic']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_ingredients[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(39774, 1363)\n",
      "CPU times: user 764 ms, sys: 12 ms, total: 776 ms\n",
      "Wall time: 772 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bigram_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "bigram_vectors = bigram_vectorizer.fit_transform(filtered_ingredients)\n",
    "print(type(bigram_vectors))\n",
    "assert(len(all_recipes) == bigram_vectors.shape[0])\n",
    "print(bigram_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c9a1c416da29b045115119de9ac4b2d69f4d780"
   },
   "source": [
    "# Generating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "_uuid": "a28369751bb4779af63f515321a1d4089b7f83b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingred_len</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29565</th>\n",
       "      <td>chinese</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15528</th>\n",
       "      <td>italian</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38015</th>\n",
       "      <td>cajun_creole</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20511</th>\n",
       "      <td>italian</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44111</th>\n",
       "      <td>chinese</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cuisine  ingred_len  train\n",
       "29565       chinese          17      1\n",
       "15528       italian           8      1\n",
       "38015  cajun_creole          15      1\n",
       "20511       italian          19      1\n",
       "44111       chinese          14      1"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_feature_columns = ['ingred_len']\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "_uuid": "d0b8919c8943aa6ba3cfb97b88167ab55be59f03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 1)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = meta[meta_feature_columns].values\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7735bb9d807b9b24ac297ae62b34a7ab2d198e1"
   },
   "source": [
    "# Assembling model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "_uuid": "91bdfcc1f38cebe07736d328b7eed60f18cae4fd"
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "_uuid": "e931eb21b3d73d996854b6c80bf14bb2fac6ace5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert(all_vectors.shape[0] == features.shape[0])\n",
    "data = sp.sparse.hstack([all_vectors, bigram_vectors, sp.sparse.csr_matrix(features)], format='csr')\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "_uuid": "e13b10a22e5e00c99bc596ad2d7bdcd7a069e552"
   },
   "outputs": [],
   "source": [
    "cousine_names = [r['cuisine'] for r in train]\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(cousine_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "_uuid": "df055b407e72458e452ffc96bc0be279919d542a"
   },
   "outputs": [],
   "source": [
    "train_data = data[:len(labels)]\n",
    "test_data = data[len(labels):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9c9645f0bb00c8f00314ba74f0a705a15adbbc64"
   },
   "source": [
    "# Model training and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "_uuid": "ccdee02475b6e3036ba700d6bfcd76e72cb61ce0"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b15ea02f8087835cc1c33c846cd0b9912f41f60",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 64 rounds.\n",
      "[16]\tvalid_0's multi_logloss: 1.15359\tvalid_0's multi_error: 0.3006\n",
      "[32]\tvalid_0's multi_logloss: 1.10612\tvalid_0's multi_error: 0.283678\n",
      "[48]\tvalid_0's multi_logloss: 0.982007\tvalid_0's multi_error: 0.26982\n",
      "[64]\tvalid_0's multi_logloss: 0.954849\tvalid_0's multi_error: 0.256362\n",
      "[80]\tvalid_0's multi_logloss: 0.920612\tvalid_0's multi_error: 0.253831\n",
      "[96]\tvalid_0's multi_logloss: 0.87845\tvalid_0's multi_error: 0.247035\n",
      "[112]\tvalid_0's multi_logloss: 0.890867\tvalid_0's multi_error: 0.246636\n",
      "[128]\tvalid_0's multi_logloss: 0.891077\tvalid_0's multi_error: 0.247302\n",
      "[144]\tvalid_0's multi_logloss: 0.857787\tvalid_0's multi_error: 0.242505\n",
      "[160]\tvalid_0's multi_logloss: 0.864567\tvalid_0's multi_error: 0.242638\n",
      "[176]\tvalid_0's multi_logloss: 0.841042\tvalid_0's multi_error: 0.241306\n",
      "[192]\tvalid_0's multi_logloss: 0.833041\tvalid_0's multi_error: 0.238241\n",
      "[208]\tvalid_0's multi_logloss: 0.844134\tvalid_0's multi_error: 0.240906\n",
      "[224]\tvalid_0's multi_logloss: 0.820748\tvalid_0's multi_error: 0.234377\n",
      "[240]\tvalid_0's multi_logloss: 0.815188\tvalid_0's multi_error: 0.232378\n",
      "[256]\tvalid_0's multi_logloss: 0.812264\tvalid_0's multi_error: 0.233711\n",
      "[272]\tvalid_0's multi_logloss: 0.80879\tvalid_0's multi_error: 0.234244\n",
      "[288]\tvalid_0's multi_logloss: 0.806904\tvalid_0's multi_error: 0.233045\n",
      "[304]\tvalid_0's multi_logloss: 0.805106\tvalid_0's multi_error: 0.233178\n",
      "[320]\tvalid_0's multi_logloss: 0.804915\tvalid_0's multi_error: 0.233178\n",
      "[336]\tvalid_0's multi_logloss: 0.805071\tvalid_0's multi_error: 0.233045\n",
      "[352]\tvalid_0's multi_logloss: 0.80487\tvalid_0's multi_error: 0.232378\n",
      "[368]\tvalid_0's multi_logloss: 0.804143\tvalid_0's multi_error: 0.232911\n",
      "[384]\tvalid_0's multi_logloss: 0.805418\tvalid_0's multi_error: 0.231845\n",
      "[400]\tvalid_0's multi_logloss: 0.805105\tvalid_0's multi_error: 0.230913\n",
      "[416]\tvalid_0's multi_logloss: 0.805545\tvalid_0's multi_error: 0.231046\n",
      "[432]\tvalid_0's multi_logloss: 0.804607\tvalid_0's multi_error: 0.230913\n",
      "[448]\tvalid_0's multi_logloss: 0.804421\tvalid_0's multi_error: 0.232645\n",
      "[464]\tvalid_0's multi_logloss: 0.805401\tvalid_0's multi_error: 0.232378\n",
      "Early stopping, best iteration is:\n",
      "[403]\tvalid_0's multi_logloss: 0.805196\tvalid_0's multi_error: 0.229714\n",
      "Fold 0, val_accuracy=0.7682878081279148\n",
      "Training until validation scores don't improve for 64 rounds.\n",
      "[16]\tvalid_0's multi_logloss: 1.17773\tvalid_0's multi_error: 0.306452\n",
      "[32]\tvalid_0's multi_logloss: 1.13432\tvalid_0's multi_error: 0.292189\n",
      "[48]\tvalid_0's multi_logloss: 1.01071\tvalid_0's multi_error: 0.275127\n",
      "[64]\tvalid_0's multi_logloss: 0.9876\tvalid_0's multi_error: 0.265662\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "splitter = StratifiedKFold(n_splits=4, random_state=42, shuffle=True)\n",
    "results = []\n",
    "for fold, (train_idx_, eval_idx_) in enumerate(splitter.split(train_data, labels)):\n",
    "    train_X_, train_y_ = train_data[train_idx_], labels[train_idx_]\n",
    "    eval_X_, eval_y_ = train_data[eval_idx_], labels[eval_idx_]\n",
    "    model_params = {\n",
    "        'objective': 'multiclass',\n",
    "        'boosting': 'dart',\n",
    "        'learning_rate': 0.2137,\n",
    "        'n_estimators': 512,\n",
    "        'n_classes': len(np.unique(labels)),\n",
    "        'n_jobs': 16,\n",
    "        'random_state': 42,\n",
    "        'silent': True,\n",
    "    }\n",
    "    fit_params = {\n",
    "        'eval_set': (eval_X_, eval_y_),\n",
    "        'eval_metric': 'multi_error',\n",
    "        'early_stopping_rounds': 64,\n",
    "        'verbose': 16,\n",
    "    }\n",
    "    model = LGBMClassifier(**model_params)\n",
    "    model.fit(train_X_, train_y_, **fit_params)\n",
    "    preds = model.predict(eval_X_, num_iteration=model.best_iteration_)\n",
    "    score = accuracy_score(eval_y_, preds)\n",
    "    conf_mat = confusion_matrix(eval_y_, preds)\n",
    "    print(f\"Fold {fold}, val_accuracy={score}\")\n",
    "    results.append({\n",
    "        'score': score,\n",
    "        'model': model,\n",
    "        'confusion_matrix': conf_mat\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7682878081279148,\n",
       " 0.7537989869368168,\n",
       " 0.7504335067360277,\n",
       " 0.7612059765208111]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r['score'] for r in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2e9a31a8ec420b42d89d330ecff175b0c035c597"
   },
   "source": [
    "# Submission generation\n",
    "For a start, we will just perform simple voting from out-of-fold predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "f2fbe0aef926a5fc301bb44ad8e3d1e7b561faf4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9774, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24888</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43564</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21898</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6991</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37700</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  cuisine\n",
       "0  24888  italian\n",
       "1  43564  italian\n",
       "2  21898  italian\n",
       "3   6991  italian\n",
       "4  37700  italian"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_subm = pd.read_csv('./input/sample_submission.csv')\n",
    "print(sample_subm.shape)\n",
    "sample_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "49db9a3cabb9aef01b9eaf199c784300ad04ceb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label encored: LabelEncoder()\n",
      "Using result ids: [24888, 43564, 21898, 6991, 37700, 43546, 20544]...\n"
     ]
    }
   ],
   "source": [
    "result_ids = [r['id'] for r in test]\n",
    "print(f\"Using label encored: {label_encoder}\")\n",
    "print(f\"Using result ids: {result_ids[:7]}...\")\n",
    "\n",
    "def generate_predictions(model_data) -> pd.DataFrame:\n",
    "    model = model_data['model']\n",
    "    preds = model.predict(test_data, num_iteration=model.best_iteration_)\n",
    "    pred_names = label_encoder.inverse_transform(preds)\n",
    "    return pd.DataFrame({\n",
    "        'id': result_ids,\n",
    "        'cuisine': pred_names\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "96a8806b1051298f98bbd4de83e5ed45ff44804d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 444 ms, total: 22.8 s\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subm_dfs = [generate_predictions(model_data) for model_data in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "f2dec1a2da5e5321d8f87942a40c669179b98236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58644, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24888</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43564</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21898</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6991</td>\n",
       "      <td>moroccan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37700</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   cuisine\n",
       "0  24888   italian\n",
       "1  43564   spanish\n",
       "2  21898   italian\n",
       "3   6991  moroccan\n",
       "4  37700   spanish"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm = pd.concat(subm_dfs)\n",
    "print(subm.shape)\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "6373ca7ac1f0ca1dd6c21168cf9182174405ecfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stats.mode([1,2,2,3]).mode[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "fec6d58ff92ba91fcdd794d8bc4da153325aab17"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kk385830/miniconda3/envs/kaggle-cooking/lib/python3.6/site-packages/scipy/stats/stats.py:248: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.12 s, sys: 192 ms, total: 3.31 s\n",
      "Wall time: 3.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_sf = subm.groupby('id').cuisine.apply(lambda arr: sp.stats.mode(arr).mode[0])\n",
    "subm_final = pd.DataFrame({\n",
    "    'Id': _sf.index,\n",
    "    'cuisine': _sf.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "cf939f3ee6838a64eb5248c8501d52a1bfdedc27",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id      cuisine\n",
       "0  16       indian\n",
       "1  22      mexican\n",
       "2  24  southern_us\n",
       "3  32     japanese\n",
       "4  48       indian"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "5a69b9c80bca5e5f3db5cfd540f0b9194d42ddc2"
   },
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "assert(subm_final.notna().all().all())\n",
    "assert(sorted(sample_subm['Id'].unique()) == sorted(subm_final['Id'].unique()))\n",
    "assert(sample_subm.shape == subm_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_uuid": "313483786f339f90463372c7521c19febffde838"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./submissions/LGBM-cvmean=0.7815-cvstd=0.0079.csv'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [model_data['score'] for model_data in results]\n",
    "mean_cv_score = np.mean(scores)\n",
    "std_cv_score = np.std(scores)\n",
    "model_name = 'LGBM'\n",
    "subm_filename = f'{model_name}-cvmean={mean_cv_score:.4f}-cvstd={std_cv_score:.4f}.csv'\n",
    "subm_path = os.path.join('./submissions/', subm_filename)\n",
    "subm_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_uuid": "93117cab164c073d5582244e4ae2903f94a1243e"
   },
   "outputs": [],
   "source": [
    "subm_final.to_csv(subm_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 136k/136k [00:02<00:00, 53.8kB/s]\n",
      "Successfully submitted to ML1819 - What's Cooking?"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -f {subm_path} -m \"Baseline\" ml1819-whats-cooking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "90d7062a70263bb807645d9e965cf37413e745ad"
   },
   "source": [
    "# Possible improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a baseline, we have only vectorized words, so multi-word ingredients are treated the same as single-word ones - \n",
    "  it may be beneficial to separate the ingredient and its modifiers\n",
    "- TfIdf does not take position on the list into account - need to try other vectorization techniques\n",
    "- Testing other models: NNs in particular might work well on such dataset - if well-made we can use them \n",
    "  to take order and comma-separation of ingredients vs their modifiers into account"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
