{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = json.load(open('./input/cooking_train.json', 'r'))\n",
    "test = json.load(open('./input/cooking_test.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "36475ab00914ab8f9c624f2a187ebc21ce66d059"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "8d2882cfba41d869edc2dfb4f63daca74ae43c2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9774"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "f37dbc88b01ff254ad72720ad8eb7f52e325206e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'chinese',\n",
       " 'id': 29565,\n",
       " 'ingredients': ['romaine lettuce',\n",
       "  'sliced almonds',\n",
       "  'vegetable oil',\n",
       "  'scallions',\n",
       "  'soy sauce',\n",
       "  'cooked chicken',\n",
       "  'napa cabbage',\n",
       "  'chopped cilantro fresh',\n",
       "  'sugar',\n",
       "  'sesame seeds',\n",
       "  'wonton wrappers',\n",
       "  'fresh lemon juice',\n",
       "  'white vinegar',\n",
       "  'black pepper',\n",
       "  'sesame oil',\n",
       "  'salt',\n",
       "  'snow peas']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train + test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af77eb4e2182248584f933db2ae7b7a5d8da39d8"
   },
   "source": [
    "## Count unique ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "c72005240bada1f90c5650ebf3733e74ce97bb60"
   },
   "outputs": [],
   "source": [
    "train_meta = pd.DataFrame(index=[r['id'] for r in train], data={\n",
    "    'ingred_len': [len(r['ingredients']) for r in train],\n",
    "    'cuisine': [r['cuisine'] for r in train],\n",
    "    'train': 1\n",
    "})\n",
    "\n",
    "test_meta = pd.DataFrame(index=[r['id'] for r in test], data={\n",
    "    'ingred_len': [len(r['ingredients']) for r in test],\n",
    "    'train': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "29c6f2be9088b65f0509315ee4ebe54d599db7ad",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingred_len</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29565</th>\n",
       "      <td>17</td>\n",
       "      <td>chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15528</th>\n",
       "      <td>8</td>\n",
       "      <td>italian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38015</th>\n",
       "      <td>15</td>\n",
       "      <td>cajun_creole</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20511</th>\n",
       "      <td>19</td>\n",
       "      <td>italian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44111</th>\n",
       "      <td>14</td>\n",
       "      <td>chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ingred_len       cuisine  train\n",
       "29565          17       chinese      1\n",
       "15528           8       italian      1\n",
       "38015          15  cajun_creole      1\n",
       "20511          19       italian      1\n",
       "44111          14       chinese      1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "b9d3f230fbb4a59d9e394eb3aa0f4a2e8c9e4e6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39774"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.concat([train_meta, test_meta], sort=True)\n",
    "len(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:15<00:00, 1989.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.1 s, sys: 524 ms, total: 15.6 s\n",
      "Wall time: 15.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ingred_cuisine_dfs = [\n",
    "    pd.DataFrame({\n",
    "        'ingredient': recipe['ingredients'],\n",
    "        recipe['cuisine']: 1\n",
    "    }) for recipe in tqdm(train)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.7 s, sys: 700 ms, total: 31.4 s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ingredient_cuisines = pd.concat(ingred_cuisine_dfs, sort=False).fillna(0).groupby('ingredient').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chinese</th>\n",
       "      <th>italian</th>\n",
       "      <th>cajun_creole</th>\n",
       "      <th>southern_us</th>\n",
       "      <th>spanish</th>\n",
       "      <th>british</th>\n",
       "      <th>mexican</th>\n",
       "      <th>korean</th>\n",
       "      <th>indian</th>\n",
       "      <th>thai</th>\n",
       "      <th>irish</th>\n",
       "      <th>filipino</th>\n",
       "      <th>greek</th>\n",
       "      <th>jamaican</th>\n",
       "      <th>vietnamese</th>\n",
       "      <th>french</th>\n",
       "      <th>moroccan</th>\n",
       "      <th>japanese</th>\n",
       "      <th>russian</th>\n",
       "      <th>brazilian</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ingredient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(    oz.) tomato sauce</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(   oz.) tomato paste</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(10 oz.) frozen chopped spinach</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(14.5 oz.) diced tomatoes</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(15 oz.) refried beans</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 chinese  italian  cajun_creole  southern_us  \\\n",
       "ingredient                                                                     \n",
       "(    oz.) tomato sauce               0.0      6.0           1.0          0.0   \n",
       "(   oz.) tomato paste                0.0      1.0           0.0          0.0   \n",
       "(10 oz.) frozen chopped spinach      0.0      3.0           0.0          0.0   \n",
       "(14.5 oz.) diced tomatoes            0.0      0.0           0.0          0.0   \n",
       "(15 oz.) refried beans               0.0      0.0           0.0          0.0   \n",
       "\n",
       "                                 spanish  british  mexican  korean  indian  \\\n",
       "ingredient                                                                   \n",
       "(    oz.) tomato sauce               0.0      0.0      1.0     0.0     0.0   \n",
       "(   oz.) tomato paste                0.0      0.0      2.0     0.0     2.0   \n",
       "(10 oz.) frozen chopped spinach      0.0      0.0      0.0     0.0     0.0   \n",
       "(14.5 oz.) diced tomatoes            0.0      0.0      2.0     0.0     0.0   \n",
       "(15 oz.) refried beans               0.0      0.0      2.0     0.0     0.0   \n",
       "\n",
       "                                 thai  irish  filipino  greek  jamaican  \\\n",
       "ingredient                                                                \n",
       "(    oz.) tomato sauce            0.0    0.0       0.0    0.0       0.0   \n",
       "(   oz.) tomato paste             0.0    0.0       0.0    0.0       0.0   \n",
       "(10 oz.) frozen chopped spinach   0.0    0.0       0.0    0.0       0.0   \n",
       "(14.5 oz.) diced tomatoes         0.0    0.0       0.0    0.0       0.0   \n",
       "(15 oz.) refried beans            0.0    0.0       0.0    0.0       0.0   \n",
       "\n",
       "                                 vietnamese  french  moroccan  japanese  \\\n",
       "ingredient                                                                \n",
       "(    oz.) tomato sauce                  0.0     0.0       0.0       0.0   \n",
       "(   oz.) tomato paste                   0.0     0.0       0.0       0.0   \n",
       "(10 oz.) frozen chopped spinach         0.0     0.0       0.0       0.0   \n",
       "(14.5 oz.) diced tomatoes               0.0     0.0       0.0       0.0   \n",
       "(15 oz.) refried beans                  0.0     0.0       0.0       0.0   \n",
       "\n",
       "                                 russian  brazilian  \n",
       "ingredient                                           \n",
       "(    oz.) tomato sauce               0.0        0.0  \n",
       "(   oz.) tomato paste                0.0        0.0  \n",
       "(10 oz.) frozen chopped spinach      0.0        0.0  \n",
       "(14.5 oz.) diced tomatoes            0.0        0.0  \n",
       "(15 oz.) refried beans               0.0        0.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredient_cuisines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze what actually is in the labels - some signs such as brackets can be easily removed to eliminate noise from the data. If multiple labels contain numerical values, we can easily separate them into meaningful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_cuisines['count_notalpha'] = [len(re.findall('[^a-zA-Z\\s]', i)) for i in ingredient_cuisines.index]\n",
    "ingredient_cuisines['count_numbers'] = [len(re.findall('\\d+', i)) for i in ingredient_cuisines.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min     0.000000\n",
       "max     7.000000\n",
       "mean    0.085266\n",
       "Name: count_notalpha, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredient_cuisines['count_notalpha'].agg(['min', 'max', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min     0.000000\n",
       "max     4.000000\n",
       "mean    0.006239\n",
       "Name: count_numbers, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredient_cuisines['count_numbers'].agg(['min', 'max', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ingredient_cuisines[ingredient_cuisines['count_numbers'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2baaa402da2e8c3f810fe815c0d9dcea853c78d"
   },
   "source": [
    "# Generating vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_uuid": "c35b10b794d1b696ac13f5d8059fa366c011a630"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "_uuid": "fdf21c3e0736910d021c9a20430e8a182ea1fbb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39774\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 940 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_recipes = train + test\n",
    "print(len(all_recipes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ingredients(recipe_list: List[str]) -> str:\n",
    "    keep_text_ws = lambda ingredient: \"\".join(re.findall('[a-zA-Z\\s]', ingredient))\n",
    "    strip_ingredient = lambda ingredient: \"\".join([word.lower() for word in keep_text_ws(ingredient).split(\" \")])\n",
    "    return \", \".join([strip_ingredient(ingredient) for ingredient in recipe_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'romainelettuce, slicedalmonds, vegetableoil, scallions, soysauce, cookedchicken, napacabbage, choppedcilantrofresh, sugar, sesameseeds, wontonwrappers, freshlemonjuice, whitevinegar, blackpepper, sesameoil, salt, snowpeas'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_ingredients(all_recipes[0]['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "_uuid": "eee5bafd4d592329dd8d08141d48419ccdca117c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(1, 6650)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "all_ingredients = [preprocess_ingredients(r['ingredients']) for r in all_recipes]\n",
    "all_vectors = vectorizer.fit_transform(all_ingredients)\n",
    "print(type(all_vectors))\n",
    "assert(len(all_recipes) == all_vectors.shape[0])\n",
    "print(all_vectors[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c9a1c416da29b045115119de9ac4b2d69f4d780"
   },
   "source": [
    "# Generating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "_uuid": "a28369751bb4779af63f515321a1d4089b7f83b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingred_len</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29565</th>\n",
       "      <td>chinese</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15528</th>\n",
       "      <td>italian</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38015</th>\n",
       "      <td>cajun_creole</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20511</th>\n",
       "      <td>italian</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44111</th>\n",
       "      <td>chinese</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cuisine  ingred_len  train\n",
       "29565       chinese          17      1\n",
       "15528       italian           8      1\n",
       "38015  cajun_creole          15      1\n",
       "20511       italian          19      1\n",
       "44111       chinese          14      1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_feature_columns = ['ingred_len']\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "_uuid": "d0b8919c8943aa6ba3cfb97b88167ab55be59f03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = meta[meta_feature_columns].values\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7735bb9d807b9b24ac297ae62b34a7ab2d198e1"
   },
   "source": [
    "# Assembling model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "_uuid": "91bdfcc1f38cebe07736d328b7eed60f18cae4fd"
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "_uuid": "e931eb21b3d73d996854b6c80bf14bb2fac6ace5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert(all_vectors.shape[0] == features.shape[0])\n",
    "data = sp.sparse.hstack([all_vectors, sp.sparse.csr_matrix(features)], format='csr')\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "_uuid": "e13b10a22e5e00c99bc596ad2d7bdcd7a069e552"
   },
   "outputs": [],
   "source": [
    "cousine_names = [r['cuisine'] for r in train]\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(cousine_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "_uuid": "df055b407e72458e452ffc96bc0be279919d542a"
   },
   "outputs": [],
   "source": [
    "train_data = data[:len(labels)]\n",
    "test_data = data[len(labels):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9c9645f0bb00c8f00314ba74f0a705a15adbbc64"
   },
   "source": [
    "# Model training and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "_uuid": "ccdee02475b6e3036ba700d6bfcd76e72cb61ce0"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b15ea02f8087835cc1c33c846cd0b9912f41f60",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 64 rounds.\n",
      "[16]\tvalid_0's multi_error: 0.322185\tvalid_0's multi_logloss: 1.23227\n",
      "[32]\tvalid_0's multi_error: 0.309793\tvalid_0's multi_logloss: 1.20159\n",
      "[48]\tvalid_0's multi_error: 0.292205\tvalid_0's multi_logloss: 1.0781\n",
      "[64]\tvalid_0's multi_error: 0.281279\tvalid_0's multi_logloss: 1.05662\n",
      "[80]\tvalid_0's multi_error: 0.278614\tvalid_0's multi_logloss: 1.01923\n",
      "[96]\tvalid_0's multi_error: 0.269554\tvalid_0's multi_logloss: 0.973676\n",
      "[112]\tvalid_0's multi_error: 0.268754\tvalid_0's multi_logloss: 0.990077\n",
      "[128]\tvalid_0's multi_error: 0.271686\tvalid_0's multi_logloss: 0.990391\n",
      "[144]\tvalid_0's multi_error: 0.262625\tvalid_0's multi_logloss: 0.950828\n",
      "[160]\tvalid_0's multi_error: 0.263824\tvalid_0's multi_logloss: 0.959737\n",
      "[176]\tvalid_0's multi_error: 0.25956\tvalid_0's multi_logloss: 0.931005\n",
      "[192]\tvalid_0's multi_error: 0.259027\tvalid_0's multi_logloss: 0.922669\n",
      "[208]\tvalid_0's multi_error: 0.258628\tvalid_0's multi_logloss: 0.936602\n",
      "[224]\tvalid_0's multi_error: 0.252898\tvalid_0's multi_logloss: 0.904657\n",
      "[240]\tvalid_0's multi_error: 0.25463\tvalid_0's multi_logloss: 0.894602\n",
      "[256]\tvalid_0's multi_error: 0.252498\tvalid_0's multi_logloss: 0.888311\n",
      "[272]\tvalid_0's multi_error: 0.251965\tvalid_0's multi_logloss: 0.884795\n",
      "[288]\tvalid_0's multi_error: 0.251566\tvalid_0's multi_logloss: 0.881366\n",
      "[304]\tvalid_0's multi_error: 0.250899\tvalid_0's multi_logloss: 0.876095\n",
      "[320]\tvalid_0's multi_error: 0.2505\tvalid_0's multi_logloss: 0.871326\n",
      "[336]\tvalid_0's multi_error: 0.249434\tvalid_0's multi_logloss: 0.872875\n",
      "[352]\tvalid_0's multi_error: 0.2493\tvalid_0's multi_logloss: 0.872231\n",
      "[368]\tvalid_0's multi_error: 0.249034\tvalid_0's multi_logloss: 0.87293\n",
      "Early stopping, best iteration is:\n",
      "[318]\tvalid_0's multi_error: 0.2497\tvalid_0's multi_logloss: 0.870639\n",
      "Fold 0, val_accuracy=0.7481678880746169\n",
      "Training until validation scores don't improve for 64 rounds.\n",
      "[16]\tvalid_0's multi_error: 0.324314\tvalid_0's multi_logloss: 1.25465\n",
      "[32]\tvalid_0's multi_error: 0.308718\tvalid_0's multi_logloss: 1.22282\n",
      "[48]\tvalid_0's multi_error: 0.294322\tvalid_0's multi_logloss: 1.10451\n",
      "[64]\tvalid_0's multi_error: 0.282591\tvalid_0's multi_logloss: 1.0814\n",
      "[80]\tvalid_0's multi_error: 0.279659\tvalid_0's multi_logloss: 1.04502\n",
      "[96]\tvalid_0's multi_error: 0.27566\tvalid_0's multi_logloss: 1.00427\n",
      "[112]\tvalid_0's multi_error: 0.27606\tvalid_0's multi_logloss: 1.01992\n",
      "[128]\tvalid_0's multi_error: 0.275393\tvalid_0's multi_logloss: 1.02034\n",
      "[144]\tvalid_0's multi_error: 0.274194\tvalid_0's multi_logloss: 0.984806\n",
      "[160]\tvalid_0's multi_error: 0.273794\tvalid_0's multi_logloss: 0.992316\n",
      "[176]\tvalid_0's multi_error: 0.270861\tvalid_0's multi_logloss: 0.966845\n",
      "[192]\tvalid_0's multi_error: 0.269395\tvalid_0's multi_logloss: 0.95889\n",
      "[208]\tvalid_0's multi_error: 0.269128\tvalid_0's multi_logloss: 0.9715\n",
      "[224]\tvalid_0's multi_error: 0.265796\tvalid_0's multi_logloss: 0.941817\n",
      "[240]\tvalid_0's multi_error: 0.265129\tvalid_0's multi_logloss: 0.933702\n",
      "[256]\tvalid_0's multi_error: 0.26313\tvalid_0's multi_logloss: 0.928769\n",
      "[272]\tvalid_0's multi_error: 0.262997\tvalid_0's multi_logloss: 0.925938\n",
      "[288]\tvalid_0's multi_error: 0.261797\tvalid_0's multi_logloss: 0.922479\n",
      "[304]\tvalid_0's multi_error: 0.26233\tvalid_0's multi_logloss: 0.920047\n",
      "[320]\tvalid_0's multi_error: 0.260064\tvalid_0's multi_logloss: 0.917092\n",
      "[336]\tvalid_0's multi_error: 0.259797\tvalid_0's multi_logloss: 0.917185\n",
      "[352]\tvalid_0's multi_error: 0.260331\tvalid_0's multi_logloss: 0.915941\n",
      "[368]\tvalid_0's multi_error: 0.260197\tvalid_0's multi_logloss: 0.916695\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "splitter = StratifiedKFold(n_splits=4, random_state=42, shuffle=True)\n",
    "results = []\n",
    "for fold, (train_idx_, eval_idx_) in enumerate(splitter.split(train_data, labels)):\n",
    "    train_X_, train_y_ = train_data[train_idx_], labels[train_idx_]\n",
    "    eval_X_, eval_y_ = train_data[eval_idx_], labels[eval_idx_]\n",
    "    model_params = {\n",
    "        'objective': 'multiclass',\n",
    "        'boosting': 'dart',\n",
    "        'learning_rate': 0.2137,\n",
    "        'n_estimators': 512,\n",
    "        'n_classes': len(np.unique(labels)),\n",
    "        'n_jobs': 16,\n",
    "        'random_state': 42,\n",
    "        'silent': True,\n",
    "    }\n",
    "    fit_params = {\n",
    "        'eval_set': (eval_X_, eval_y_),\n",
    "        'eval_metric': 'multi_error',\n",
    "        'early_stopping_rounds': 64,\n",
    "        'verbose': 16,\n",
    "    }\n",
    "    model = LGBMClassifier(**model_params)\n",
    "    model.fit(train_X_, train_y_, **fit_params)\n",
    "    score = model.score(eval_X_, eval_y_)\n",
    "    print(f\"Fold {fold}, val_accuracy={score}\")\n",
    "    results.append({\n",
    "        'score': score,\n",
    "        'model': model\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2e9a31a8ec420b42d89d330ecff175b0c035c597"
   },
   "source": [
    "# Submission generation\n",
    "For a start, we will just perform simple voting from out-of-fold predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "f2fbe0aef926a5fc301bb44ad8e3d1e7b561faf4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9774, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24888</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43564</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21898</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6991</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37700</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  cuisine\n",
       "0  24888  italian\n",
       "1  43564  italian\n",
       "2  21898  italian\n",
       "3   6991  italian\n",
       "4  37700  italian"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_subm = pd.read_csv('./input/sample_submission.csv')\n",
    "print(sample_subm.shape)\n",
    "sample_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "49db9a3cabb9aef01b9eaf199c784300ad04ceb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label encored: LabelEncoder()\n",
      "Using result ids: [24888, 43564, 21898, 6991, 37700, 43546, 20544]...\n"
     ]
    }
   ],
   "source": [
    "result_ids = [r['id'] for r in test]\n",
    "print(f\"Using label encored: {label_encoder}\")\n",
    "print(f\"Using result ids: {result_ids[:7]}...\")\n",
    "\n",
    "def generate_predictions(model_data) -> pd.DataFrame:\n",
    "    model = model_data['model']\n",
    "    preds = model.predict(test_data, num_iteration=model.best_iteration_)\n",
    "    pred_names = label_encoder.inverse_transform(preds)\n",
    "    return pd.DataFrame({\n",
    "        'id': result_ids,\n",
    "        'cuisine': pred_names\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "96a8806b1051298f98bbd4de83e5ed45ff44804d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 444 ms, total: 22.8 s\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subm_dfs = [generate_predictions(model_data) for model_data in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "f2dec1a2da5e5321d8f87942a40c669179b98236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58644, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24888</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43564</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21898</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6991</td>\n",
       "      <td>moroccan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37700</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   cuisine\n",
       "0  24888   italian\n",
       "1  43564   spanish\n",
       "2  21898   italian\n",
       "3   6991  moroccan\n",
       "4  37700   spanish"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm = pd.concat(subm_dfs)\n",
    "print(subm.shape)\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "6373ca7ac1f0ca1dd6c21168cf9182174405ecfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stats.mode([1,2,2,3]).mode[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "fec6d58ff92ba91fcdd794d8bc4da153325aab17"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kk385830/miniconda3/envs/kaggle-cooking/lib/python3.6/site-packages/scipy/stats/stats.py:248: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.12 s, sys: 192 ms, total: 3.31 s\n",
      "Wall time: 3.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_sf = subm.groupby('id').cuisine.apply(lambda arr: sp.stats.mode(arr).mode[0])\n",
    "subm_final = pd.DataFrame({\n",
    "    'Id': _sf.index,\n",
    "    'cuisine': _sf.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "cf939f3ee6838a64eb5248c8501d52a1bfdedc27",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id      cuisine\n",
       "0  16       indian\n",
       "1  22      mexican\n",
       "2  24  southern_us\n",
       "3  32     japanese\n",
       "4  48       indian"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "5a69b9c80bca5e5f3db5cfd540f0b9194d42ddc2"
   },
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "assert(subm_final.notna().all().all())\n",
    "assert(sorted(sample_subm['Id'].unique()) == sorted(subm_final['Id'].unique()))\n",
    "assert(sample_subm.shape == subm_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_uuid": "313483786f339f90463372c7521c19febffde838"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./submissions/LGBM-cvmean=0.7815-cvstd=0.0079.csv'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [model_data['score'] for model_data in results]\n",
    "mean_cv_score = np.mean(scores)\n",
    "std_cv_score = np.std(scores)\n",
    "model_name = 'LGBM'\n",
    "subm_filename = f'{model_name}-cvmean={mean_cv_score:.4f}-cvstd={std_cv_score:.4f}.csv'\n",
    "subm_path = os.path.join('./submissions/', subm_filename)\n",
    "subm_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_uuid": "93117cab164c073d5582244e4ae2903f94a1243e"
   },
   "outputs": [],
   "source": [
    "subm_final.to_csv(subm_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 136k/136k [00:02<00:00, 53.8kB/s]\n",
      "Successfully submitted to ML1819 - What's Cooking?"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -f {subm_path} -m \"Baseline\" ml1819-whats-cooking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "90d7062a70263bb807645d9e965cf37413e745ad"
   },
   "source": [
    "# Possible improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a baseline, we have only vectorized words, so multi-word ingredients are treated the same as single-word ones - \n",
    "  it may be beneficial to separate the ingredient and its modifiers\n",
    "- TfIdf does not take position on the list into account - need to try other vectorization techniques\n",
    "- Testing other models: NNs in particular might work well on such dataset - if well-made we can use them \n",
    "  to take order and comma-separation of ingredients vs their modifiers into account"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
