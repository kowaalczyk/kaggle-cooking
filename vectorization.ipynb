{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = json.load(open('./input/cooking_train.json', 'r'))\n",
    "test = json.load(open('./input/cooking_test.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "36475ab00914ab8f9c624f2a187ebc21ce66d059"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "8d2882cfba41d869edc2dfb4f63daca74ae43c2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9774"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "f37dbc88b01ff254ad72720ad8eb7f52e325206e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'chinese',\n",
       " 'id': 29565,\n",
       " 'ingredients': ['romaine lettuce',\n",
       "  'sliced almonds',\n",
       "  'vegetable oil',\n",
       "  'scallions',\n",
       "  'soy sauce',\n",
       "  'cooked chicken',\n",
       "  'napa cabbage',\n",
       "  'chopped cilantro fresh',\n",
       "  'sugar',\n",
       "  'sesame seeds',\n",
       "  'wonton wrappers',\n",
       "  'fresh lemon juice',\n",
       "  'white vinegar',\n",
       "  'black pepper',\n",
       "  'sesame oil',\n",
       "  'salt',\n",
       "  'snow peas']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train + test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af77eb4e2182248584f933db2ae7b7a5d8da39d8"
   },
   "source": [
    "## Count unique ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "c72005240bada1f90c5650ebf3733e74ce97bb60"
   },
   "outputs": [],
   "source": [
    "train_meta = pd.DataFrame(index=[r['id'] for r in train], data={\n",
    "    'ingred_len': [len(r['ingredients']) for r in train],\n",
    "    'cuisine': [r['cuisine'] for r in train],\n",
    "    'train': 1\n",
    "})\n",
    "\n",
    "test_meta = pd.DataFrame(index=[r['id'] for r in test], data={\n",
    "    'ingred_len': [len(r['ingredients']) for r in test],\n",
    "    'train': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "29c6f2be9088b65f0509315ee4ebe54d599db7ad",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingred_len</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29565</th>\n",
       "      <td>17</td>\n",
       "      <td>chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15528</th>\n",
       "      <td>8</td>\n",
       "      <td>italian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38015</th>\n",
       "      <td>15</td>\n",
       "      <td>cajun_creole</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20511</th>\n",
       "      <td>19</td>\n",
       "      <td>italian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44111</th>\n",
       "      <td>14</td>\n",
       "      <td>chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ingred_len       cuisine  train\n",
       "29565          17       chinese      1\n",
       "15528           8       italian      1\n",
       "38015          15  cajun_creole      1\n",
       "20511          19       italian      1\n",
       "44111          14       chinese      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "b9d3f230fbb4a59d9e394eb3aa0f4a2e8c9e4e6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39774"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.concat([train_meta, test_meta], sort=True)\n",
    "len(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:16<00:00, 1803.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.5 s, sys: 736 ms, total: 17.2 s\n",
      "Wall time: 16.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ingred_cuisine_dfs = [\n",
    "    pd.DataFrame({\n",
    "        'ingredient': recipe['ingredients'],\n",
    "        recipe['cuisine']: 1\n",
    "    }) for recipe in tqdm(train)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.7 s, sys: 1.48 s, total: 35.2 s\n",
      "Wall time: 30.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ingredient_cuisines = pd.concat(ingred_cuisine_dfs, sort=False).fillna(0).groupby('ingredient').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chinese</th>\n",
       "      <th>italian</th>\n",
       "      <th>cajun_creole</th>\n",
       "      <th>southern_us</th>\n",
       "      <th>spanish</th>\n",
       "      <th>british</th>\n",
       "      <th>mexican</th>\n",
       "      <th>korean</th>\n",
       "      <th>indian</th>\n",
       "      <th>thai</th>\n",
       "      <th>irish</th>\n",
       "      <th>filipino</th>\n",
       "      <th>greek</th>\n",
       "      <th>jamaican</th>\n",
       "      <th>vietnamese</th>\n",
       "      <th>french</th>\n",
       "      <th>moroccan</th>\n",
       "      <th>japanese</th>\n",
       "      <th>russian</th>\n",
       "      <th>brazilian</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ingredient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(    oz.) tomato sauce</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(   oz.) tomato paste</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(10 oz.) frozen chopped spinach</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(14.5 oz.) diced tomatoes</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(15 oz.) refried beans</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 chinese  italian  cajun_creole  southern_us  \\\n",
       "ingredient                                                                     \n",
       "(    oz.) tomato sauce               0.0      6.0           1.0          0.0   \n",
       "(   oz.) tomato paste                0.0      1.0           0.0          0.0   \n",
       "(10 oz.) frozen chopped spinach      0.0      3.0           0.0          0.0   \n",
       "(14.5 oz.) diced tomatoes            0.0      0.0           0.0          0.0   \n",
       "(15 oz.) refried beans               0.0      0.0           0.0          0.0   \n",
       "\n",
       "                                 spanish  british  mexican  korean  indian  \\\n",
       "ingredient                                                                   \n",
       "(    oz.) tomato sauce               0.0      0.0      1.0     0.0     0.0   \n",
       "(   oz.) tomato paste                0.0      0.0      2.0     0.0     2.0   \n",
       "(10 oz.) frozen chopped spinach      0.0      0.0      0.0     0.0     0.0   \n",
       "(14.5 oz.) diced tomatoes            0.0      0.0      2.0     0.0     0.0   \n",
       "(15 oz.) refried beans               0.0      0.0      2.0     0.0     0.0   \n",
       "\n",
       "                                 thai  irish  filipino  greek  jamaican  \\\n",
       "ingredient                                                                \n",
       "(    oz.) tomato sauce            0.0    0.0       0.0    0.0       0.0   \n",
       "(   oz.) tomato paste             0.0    0.0       0.0    0.0       0.0   \n",
       "(10 oz.) frozen chopped spinach   0.0    0.0       0.0    0.0       0.0   \n",
       "(14.5 oz.) diced tomatoes         0.0    0.0       0.0    0.0       0.0   \n",
       "(15 oz.) refried beans            0.0    0.0       0.0    0.0       0.0   \n",
       "\n",
       "                                 vietnamese  french  moroccan  japanese  \\\n",
       "ingredient                                                                \n",
       "(    oz.) tomato sauce                  0.0     0.0       0.0       0.0   \n",
       "(   oz.) tomato paste                   0.0     0.0       0.0       0.0   \n",
       "(10 oz.) frozen chopped spinach         0.0     0.0       0.0       0.0   \n",
       "(14.5 oz.) diced tomatoes               0.0     0.0       0.0       0.0   \n",
       "(15 oz.) refried beans                  0.0     0.0       0.0       0.0   \n",
       "\n",
       "                                 russian  brazilian  \n",
       "ingredient                                           \n",
       "(    oz.) tomato sauce               0.0        0.0  \n",
       "(   oz.) tomato paste                0.0        0.0  \n",
       "(10 oz.) frozen chopped spinach      0.0        0.0  \n",
       "(14.5 oz.) diced tomatoes            0.0        0.0  \n",
       "(15 oz.) refried beans               0.0        0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredient_cuisines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze what actually is in the labels - some signs such as brackets can be easily removed to eliminate noise from the data. If multiple labels contain numerical values, we can easily separate them into meaningful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_cuisines['count_notalpha'] = [len(re.findall('[^a-zA-Z\\s]', i)) for i in ingredient_cuisines.index]\n",
    "ingredient_cuisines['count_numbers'] = [len(re.findall('\\d+', i)) for i in ingredient_cuisines.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min     0.000000\n",
       "max     7.000000\n",
       "mean    0.085266\n",
       "Name: count_notalpha, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredient_cuisines['count_notalpha'].agg(['min', 'max', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min     0.000000\n",
       "max     4.000000\n",
       "mean    0.006239\n",
       "Name: count_numbers, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredient_cuisines['count_numbers'].agg(['min', 'max', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ingredient_cuisines[ingredient_cuisines['count_numbers'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This does not seem to be imporatnt, let's eliminate as much words as possible instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6251"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ingredient_cuisines.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>épices</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>hothouse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>hoop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>hong</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>honeycomb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  count\n",
       "3386     épices      1\n",
       "1855   hothouse      1\n",
       "1852       hoop      1\n",
       "1851       hong      1\n",
       "1849  honeycomb      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = \" \".join(ingredient_cuisines.index.unique()).split(\" \")\n",
    "unique_words, counts = np.unique(all_words, return_counts=True)\n",
    "word_counts = pd.DataFrame({\n",
    "    'word': unique_words,\n",
    "    'count': counts\n",
    "}).sort_values(by='count')\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3387"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1845"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignored_words = word_counts[word_counts['count'] == 1]\n",
    "len(ignored_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, words that occur only once have should have no meaning for our model.\n",
    "This way, we can greatly reduce the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1483"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alnum_meaningful = [\n",
    "    word for word in word_counts['word'] \n",
    "    if word.isalnum() and not word in set(ignored_words['word'])\n",
    "]\n",
    "len(alnum_meaningful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2baaa402da2e8c3f810fe815c0d9dcea853c78d"
   },
   "source": [
    "# Generating vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "c35b10b794d1b696ac13f5d8059fa366c011a630"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from typing import Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "fdf21c3e0736910d021c9a20430e8a182ea1fbb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39774\n",
      "CPU times: user 0 ns, sys: 4 ms, total: 4 ms\n",
      "Wall time: 6.58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_recipes = train + test\n",
    "print(len(all_recipes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ingredients_whitelist(\n",
    "        recipes: List[dict], \n",
    "        whitelist: Set[str] = set(alnum_meaningful)\n",
    ") -> str:\n",
    "    process_ingredient = lambda ingredient: \" \".join([\n",
    "        word for word in ingredient.split(\" \") if word in whitelist\n",
    "    ])\n",
    "    process_recipe = lambda recipe: \" \".join([\n",
    "        process_ingredient(ingredient) for ingredient in recipe['ingredients']\n",
    "    ])\n",
    "    return [re.sub('\\s+', \" \", process_recipe(recipe)) for recipe in recipes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ingredients(recipe_list: List[str]) -> str:\n",
    "    keep_text_ws = lambda ingredient: \"\".join(re.findall('[a-zA-Z\\s]', ingredient))\n",
    "    strip_ingredient = lambda ingredient: \"\".join([word.lower() for word in keep_text_ws(ingredient).split(\" \")])\n",
    "    return \", \".join([strip_ingredient(ingredient) for ingredient in recipe_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'romainelettuce, slicedalmonds, vegetableoil, scallions, soysauce, cookedchicken, napacabbage, choppedcilantrofresh, sugar, sesameseeds, wontonwrappers, freshlemonjuice, whitevinegar, blackpepper, sesameoil, salt, snowpeas'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_ingredients(all_recipes[0]['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['romaine lettuce sliced almonds vegetable oil soy sauce cooked chicken napa cabbage chopped cilantro fresh sugar sesame seeds wonton wrappers fresh lemon juice white vinegar black pepper sesame oil salt snow peas']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_ingredients_whitelist(all_recipes[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_uuid": "eee5bafd4d592329dd8d08141d48419ccdca117c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(39774, 1337)\n",
      "CPU times: user 1.55 s, sys: 20 ms, total: 1.57 s\n",
      "Wall time: 1.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer()\n",
    "# all_ingredients = [preprocess_ingredients(r['ingredients']) for r in all_recipes]\n",
    "all_ingredients = preprocess_ingredients_whitelist(all_recipes)\n",
    "all_vectors = vectorizer.fit_transform(all_ingredients)\n",
    "print(type(all_vectors))\n",
    "assert(len(all_recipes) == all_vectors.shape[0])\n",
    "print(all_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c9a1c416da29b045115119de9ac4b2d69f4d780"
   },
   "source": [
    "# Generating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_uuid": "a28369751bb4779af63f515321a1d4089b7f83b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingred_len</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29565</th>\n",
       "      <td>chinese</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15528</th>\n",
       "      <td>italian</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38015</th>\n",
       "      <td>cajun_creole</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20511</th>\n",
       "      <td>italian</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44111</th>\n",
       "      <td>chinese</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cuisine  ingred_len  train\n",
       "29565       chinese          17      1\n",
       "15528       italian           8      1\n",
       "38015  cajun_creole          15      1\n",
       "20511       italian          19      1\n",
       "44111       chinese          14      1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_feature_columns = ['ingred_len']\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "d0b8919c8943aa6ba3cfb97b88167ab55be59f03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = meta[meta_feature_columns].values\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7735bb9d807b9b24ac297ae62b34a7ab2d198e1"
   },
   "source": [
    "# Assembling model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "91bdfcc1f38cebe07736d328b7eed60f18cae4fd"
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_uuid": "e931eb21b3d73d996854b6c80bf14bb2fac6ace5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert(all_vectors.shape[0] == features.shape[0])\n",
    "data = sp.sparse.hstack([all_vectors, sp.sparse.csr_matrix(features)], format='csr')\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_uuid": "e13b10a22e5e00c99bc596ad2d7bdcd7a069e552"
   },
   "outputs": [],
   "source": [
    "cousine_names = [r['cuisine'] for r in train]\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(cousine_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "_uuid": "df055b407e72458e452ffc96bc0be279919d542a"
   },
   "outputs": [],
   "source": [
    "train_data = data[:len(labels)]\n",
    "test_data = data[len(labels):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9c9645f0bb00c8f00314ba74f0a705a15adbbc64"
   },
   "source": [
    "# Model training and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "_uuid": "ccdee02475b6e3036ba700d6bfcd76e72cb61ce0"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_uuid": "0b15ea02f8087835cc1c33c846cd0b9912f41f60",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 64 rounds.\n",
      "[16]\tvalid_0's multi_logloss: 1.28911\tvalid_0's multi_error: 0.303131\n",
      "[32]\tvalid_0's multi_logloss: 1.03479\tvalid_0's multi_error: 0.268754\n",
      "[48]\tvalid_0's multi_logloss: 0.918036\tvalid_0's multi_error: 0.248501\n",
      "[64]\tvalid_0's multi_logloss: 0.857375\tvalid_0's multi_error: 0.242372\n",
      "[80]\tvalid_0's multi_logloss: 0.825538\tvalid_0's multi_error: 0.236109\n",
      "[96]\tvalid_0's multi_logloss: 0.807313\tvalid_0's multi_error: 0.232378\n",
      "[112]\tvalid_0's multi_logloss: 0.797314\tvalid_0's multi_error: 0.231712\n",
      "[128]\tvalid_0's multi_logloss: 0.791871\tvalid_0's multi_error: 0.228514\n",
      "[144]\tvalid_0's multi_logloss: 0.789347\tvalid_0's multi_error: 0.226782\n",
      "[160]\tvalid_0's multi_logloss: 0.789473\tvalid_0's multi_error: 0.226649\n",
      "[176]\tvalid_0's multi_logloss: 0.791395\tvalid_0's multi_error: 0.227182\n",
      "[192]\tvalid_0's multi_logloss: 0.794216\tvalid_0's multi_error: 0.225183\n",
      "[208]\tvalid_0's multi_logloss: 0.79752\tvalid_0's multi_error: 0.225716\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's multi_logloss: 0.788735\tvalid_0's multi_error: 0.227182\n",
      "Fold 0, val_accuracy=0.7728181212524984\n",
      "Training until validation scores don't improve for 64 rounds.\n",
      "[16]\tvalid_0's multi_logloss: 1.31137\tvalid_0's multi_error: 0.309251\n",
      "[32]\tvalid_0's multi_logloss: 1.05755\tvalid_0's multi_error: 0.281525\n",
      "[48]\tvalid_0's multi_logloss: 0.940698\tvalid_0's multi_error: 0.26393\n",
      "[64]\tvalid_0's multi_logloss: 0.882468\tvalid_0's multi_error: 0.252333\n",
      "[80]\tvalid_0's multi_logloss: 0.852503\tvalid_0's multi_error: 0.247001\n",
      "[96]\tvalid_0's multi_logloss: 0.834947\tvalid_0's multi_error: 0.241002\n",
      "[112]\tvalid_0's multi_logloss: 0.825886\tvalid_0's multi_error: 0.23887\n",
      "[128]\tvalid_0's multi_logloss: 0.821152\tvalid_0's multi_error: 0.239536\n",
      "[144]\tvalid_0's multi_logloss: 0.821236\tvalid_0's multi_error: 0.236604\n",
      "[160]\tvalid_0's multi_logloss: 0.822843\tvalid_0's multi_error: 0.23767\n",
      "[176]\tvalid_0's multi_logloss: 0.826269\tvalid_0's multi_error: 0.238203\n",
      "[192]\tvalid_0's multi_logloss: 0.830298\tvalid_0's multi_error: 0.239669\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's multi_logloss: 0.820673\tvalid_0's multi_error: 0.237537\n",
      "Fold 1, val_accuracy=0.7624633431085044\n",
      "Training until validation scores don't improve for 64 rounds.\n",
      "[16]\tvalid_0's multi_logloss: 1.32531\tvalid_0's multi_error: 0.318794\n",
      "[32]\tvalid_0's multi_logloss: 1.07076\tvalid_0's multi_error: 0.288916\n",
      "[48]\tvalid_0's multi_logloss: 0.953731\tvalid_0's multi_error: 0.272776\n",
      "[64]\tvalid_0's multi_logloss: 0.89601\tvalid_0's multi_error: 0.262372\n",
      "[80]\tvalid_0's multi_logloss: 0.866246\tvalid_0's multi_error: 0.256769\n",
      "[96]\tvalid_0's multi_logloss: 0.850644\tvalid_0's multi_error: 0.253568\n",
      "[112]\tvalid_0's multi_logloss: 0.843086\tvalid_0's multi_error: 0.251434\n",
      "[128]\tvalid_0's multi_logloss: 0.84033\tvalid_0's multi_error: 0.247966\n",
      "[144]\tvalid_0's multi_logloss: 0.840735\tvalid_0's multi_error: 0.2489\n",
      "[160]\tvalid_0's multi_logloss: 0.844802\tvalid_0's multi_error: 0.246632\n",
      "[176]\tvalid_0's multi_logloss: 0.850169\tvalid_0's multi_error: 0.245965\n",
      "[192]\tvalid_0's multi_logloss: 0.856448\tvalid_0's multi_error: 0.245298\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's multi_logloss: 0.840322\tvalid_0's multi_error: 0.2489\n",
      "Fold 2, val_accuracy=0.7511004401760705\n",
      "Training until validation scores don't improve for 64 rounds.\n",
      "[16]\tvalid_0's multi_logloss: 1.28934\tvalid_0's multi_error: 0.299493\n",
      "[32]\tvalid_0's multi_logloss: 1.03695\tvalid_0's multi_error: 0.270945\n",
      "[48]\tvalid_0's multi_logloss: 0.921576\tvalid_0's multi_error: 0.254936\n",
      "[64]\tvalid_0's multi_logloss: 0.862174\tvalid_0's multi_error: 0.246798\n",
      "[80]\tvalid_0's multi_logloss: 0.830044\tvalid_0's multi_error: 0.239194\n",
      "[96]\tvalid_0's multi_logloss: 0.813242\tvalid_0's multi_error: 0.234525\n",
      "[112]\tvalid_0's multi_logloss: 0.803328\tvalid_0's multi_error: 0.232524\n",
      "[128]\tvalid_0's multi_logloss: 0.799985\tvalid_0's multi_error: 0.232257\n",
      "[144]\tvalid_0's multi_logloss: 0.79879\tvalid_0's multi_error: 0.23119\n",
      "[160]\tvalid_0's multi_logloss: 0.799791\tvalid_0's multi_error: 0.229856\n",
      "[176]\tvalid_0's multi_logloss: 0.803427\tvalid_0's multi_error: 0.229856\n",
      "[192]\tvalid_0's multi_logloss: 0.80756\tvalid_0's multi_error: 0.229322\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's multi_logloss: 0.798488\tvalid_0's multi_error: 0.231724\n",
      "Fold 3, val_accuracy=0.7682764140875133\n",
      "CPU times: user 36min 1s, sys: 1.08 s, total: 36min 2s\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "splitter = StratifiedKFold(n_splits=4, random_state=42, shuffle=True)\n",
    "results = []\n",
    "for fold, (train_idx_, eval_idx_) in enumerate(splitter.split(train_data, labels)):\n",
    "    train_X_, train_y_ = train_data[train_idx_], labels[train_idx_]\n",
    "    eval_X_, eval_y_ = train_data[eval_idx_], labels[eval_idx_]\n",
    "    model_params = {\n",
    "        'objective': 'multiclass',\n",
    "        'n_estimators': 512,\n",
    "        'num_class': len(np.unique(labels)),\n",
    "        'n_jobs': 12,\n",
    "        'random_state': 42,\n",
    "        'silent': True,\n",
    "    }\n",
    "    fit_params = {\n",
    "        'eval_set': (eval_X_, eval_y_),\n",
    "        'eval_metric': 'multi_error',\n",
    "        'early_stopping_rounds': 64,\n",
    "        'verbose': 16,\n",
    "    }\n",
    "    model = LGBMClassifier(**model_params)\n",
    "    model.fit(train_X_, train_y_, **fit_params)\n",
    "    score = model.score(eval_X_, eval_y_)\n",
    "    print(f\"Fold {fold}, val_accuracy={score}\")\n",
    "    results.append({\n",
    "        'score': score,\n",
    "        'model': model\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2e9a31a8ec420b42d89d330ecff175b0c035c597"
   },
   "source": [
    "# Submission generation\n",
    "For a start, we will just perform simple voting from out-of-fold predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_uuid": "f2fbe0aef926a5fc301bb44ad8e3d1e7b561faf4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9774, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24888</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43564</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21898</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6991</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37700</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  cuisine\n",
       "0  24888  italian\n",
       "1  43564  italian\n",
       "2  21898  italian\n",
       "3   6991  italian\n",
       "4  37700  italian"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_subm = pd.read_csv('./input/sample_submission.csv')\n",
    "print(sample_subm.shape)\n",
    "sample_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "_uuid": "49db9a3cabb9aef01b9eaf199c784300ad04ceb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label encored: LabelEncoder()\n",
      "Using result ids: [24888, 43564, 21898, 6991, 37700, 43546, 20544]...\n"
     ]
    }
   ],
   "source": [
    "result_ids = [r['id'] for r in test]\n",
    "print(f\"Using label encored: {label_encoder}\")\n",
    "print(f\"Using result ids: {result_ids[:7]}...\")\n",
    "\n",
    "def generate_predictions(model_data) -> pd.DataFrame:\n",
    "    model = model_data['model']\n",
    "    preds = model.predict(test_data, num_iteration=model.best_iteration_)\n",
    "    pred_names = label_encoder.inverse_transform(preds)\n",
    "    return pd.DataFrame({\n",
    "        'id': result_ids,\n",
    "        'cuisine': pred_names\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "_uuid": "96a8806b1051298f98bbd4de83e5ed45ff44804d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.4 s, sys: 144 ms, total: 16.5 s\n",
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subm_dfs = [generate_predictions(model_data) for model_data in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "_uuid": "f2dec1a2da5e5321d8f87942a40c669179b98236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39096, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24888</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43564</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21898</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6991</td>\n",
       "      <td>moroccan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37700</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine\n",
       "0  24888      italian\n",
       "1  43564      spanish\n",
       "2  21898  southern_us\n",
       "3   6991     moroccan\n",
       "4  37700      spanish"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm = pd.concat(subm_dfs)\n",
    "print(subm.shape)\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "_uuid": "fec6d58ff92ba91fcdd794d8bc4da153325aab17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.43 s, sys: 96 ms, total: 2.53 s\n",
      "Wall time: 2.27 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kk385830/miniconda3/envs/kaggle-cooking/lib/python3.6/site-packages/scipy/stats/stats.py:245: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_sf = subm.groupby('id').cuisine.apply(lambda arr: sp.stats.mode(arr).mode[0])\n",
    "subm_final = pd.DataFrame({\n",
    "    'Id': _sf.index,\n",
    "    'cuisine': _sf.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "_uuid": "cf939f3ee6838a64eb5248c8501d52a1bfdedc27",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id      cuisine\n",
       "0  16       indian\n",
       "1  22      mexican\n",
       "2  24  southern_us\n",
       "3  32      chinese\n",
       "4  48       indian"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "_uuid": "5a69b9c80bca5e5f3db5cfd540f0b9194d42ddc2"
   },
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "assert(subm_final.notna().all().all())\n",
    "assert(sorted(sample_subm['Id'].unique()) == sorted(subm_final['Id'].unique()))\n",
    "assert(sample_subm.shape == subm_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "_uuid": "313483786f339f90463372c7521c19febffde838"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./submissions/LGBM-less-features-cvmean=0.7637-cvstd=0.0081.csv'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [model_data['score'] for model_data in results]\n",
    "mean_cv_score = np.mean(scores)\n",
    "std_cv_score = np.std(scores)\n",
    "model_name = 'LGBM-less-features'\n",
    "subm_filename = f'{model_name}-cvmean={mean_cv_score:.4f}-cvstd={std_cv_score:.4f}.csv'\n",
    "subm_path = os.path.join('./submissions/', subm_filename)\n",
    "subm_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "_uuid": "93117cab164c073d5582244e4ae2903f94a1243e"
   },
   "outputs": [],
   "source": [
    "subm_final.to_csv(subm_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 136k/136k [00:02<00:00, 50.8kB/s]\n",
      "Successfully submitted to ML1819 - What's Cooking?"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -f {subm_path} -m \"Less features\" ml1819-whats-cooking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "90d7062a70263bb807645d9e965cf37413e745ad"
   },
   "source": [
    "# Possible improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a baseline, we have only vectorized words, so multi-word ingredients are treated the same as single-word ones - \n",
    "  it may be beneficial to separate the ingredient and its modifiers\n",
    "- TfIdf does not take position on the list into account - need to try other vectorization techniques\n",
    "- Testing other models: NNs in particular might work well on such dataset - if well-made we can use them \n",
    "  to take order and comma-separation of ingredients vs their modifiers into account"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
